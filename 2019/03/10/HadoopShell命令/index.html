<!doctype html>
<html lang="en">

<!-- Head -->
<!doctype html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="description" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/image/favicon.jpg">
    

    <title>
        
        HadoopShell命令 |
        
        keep moving on
    </title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css">

    <!-- Custom Fonts -->
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Plugin CSS -->


    <!-- Custom CSS -->
    <!-- ↓这是stylus文件 -->
    <link rel="stylesheet" href="/lhj/css/style.css">
    <link rel="stylesheet" href="/lhj/css/home.css">
    <link rel="stylesheet" href="/lhj/css/highlight.css">
    <link rel="stylesheet" href="/lhj/css/toc.css">


</head>
<body></body>
</html>

<body>

<!-- Header -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header {
     background-image: url('/lhj/image/header.jpg'); 
	/*
	 background-image: url('');
        /*post*/
    
	*/
    }
</style>

<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- 文章 -->
                
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/lhj/tags/#hadoop" title="hadoop">hadoop</a>
                        
                    </div>
                    <h1>HadoopShell命令</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                            Posted by linhuanjie on
                        2019-03-10
                        </span>
                </div>
                <!-- 非文章 -->
                

            </div>
        </div>
    </div>
</header>

<!-- Nav -->
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/lhj/">keep moving on</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<!-- Content -->
<!-- Content -->
<div class="container">
    <div class="row">
        <!-- Post container -->

        <div class="
                col-lg-8 col-lg-offset-1
                col-md-8 col-md-offset-1
                col-sm-12
                col-xs-12
                post-container
            ">

            <h3 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h3><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs <args>的形式。 所有的的FS shell命令使用URI路径作为参数。URI格式是<em>scheme://authority/path</em>。对HDFS文件系统，scheme是<em>hdfs</em>，对本地文件系统，scheme是<em>file</em>。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如<em>/parent/child</em>可以表示成<em>hdfs://namenode:namenodeport/parent/child</em>，或者更简单的<em>/parent/child</em>（假设你配置文件中的默认值是<em>namenode:namenodeport</em>）。大多数FS Shell命令的行为和对应的Unix Shell命令类似，不同之处会在下面介绍各命令使用详情时指出。出错信息会输出到<em>stderr</em>，其他信息输出到<em>stdout</em>。</args></p>
<h3 id="cat-查看文件内容"><a href="#cat-查看文件内容" class="headerlink" title="cat - 查看文件内容"></a>cat - 查看文件内容</h3><p>使用方法：hadoop fs -cat URI [URI …]</p>
<p>将路径指定文件的内容输出到<em>stdout</em>。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -cat hdfs://host1:port1/file1 hdfs://host2:port2/file2</li>
<li>hadoop fs -cat file:///file3 /user/hadoop/file4</li>
</ul>
<p>返回值：<br>成功返回0，失败返回-1。</p>
<h3 id="chgrp-改变文件所属的组"><a href="#chgrp-改变文件所属的组" class="headerlink" title="chgrp - 改变文件所属的组"></a>chgrp - 改变文件所属的组</h3><p>使用方法：hadoop fs -chgrp [-R] GROUP URI [URI …] Change group association of files. With -R, make the change recursively through the directory structure. The user must be the owner of files, or else a super-user. Additional information is in the <a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_permissions_guide.html" target="_blank" rel="noopener">Permissions User Guide</a>. –&gt;</p>
<p>改变文件所属的组。使用-R将使改变在目录结构下递归进行。命令的使用者必须是文件的所有者或者超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_permissions_guide.html" target="_blank" rel="noopener">HDFS权限用户指南</a>。</p>
<h3 id="chmod-改变文件的权限"><a href="#chmod-改变文件的权限" class="headerlink" title="chmod - 改变文件的权限"></a>chmod - 改变文件的权限</h3><p>使用方法：hadoop fs -chmod [-R] &lt;MODE[,MODE]… | OCTALMODE&gt; URI [URI …]</p>
<p>改变文件的权限。使用-R将使改变在目录结构下递归进行。命令的使用者必须是文件的所有者或者超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_permissions_guide.html" target="_blank" rel="noopener">HDFS权限用户指南</a>。</p>
<h3 id="chown-改变文件的拥有者"><a href="#chown-改变文件的拥有者" class="headerlink" title="chown - 改变文件的拥有者"></a>chown - 改变文件的拥有者</h3><p>使用方法：hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ]</p>
<p>改变文件的拥有者。使用-R将使改变在目录结构下递归进行。命令的使用者必须是超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_permissions_guide.html" target="_blank" rel="noopener">HDFS权限用户指南</a>。</p>
<h3 id="copyFromLocal-上传本地文件"><a href="#copyFromLocal-上传本地文件" class="headerlink" title="copyFromLocal - 上传本地文件"></a>copyFromLocal - 上传本地文件</h3><p>使用方法：hadoop fs -copyFromLocal <localsrc> URI</localsrc></p>
<p>除了限定源路径是一个本地文件外，和<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html#putlink" target="_blank" rel="noopener"><strong>put</strong></a>命令相似。</p>
<h3 id="copyToLocal-下载文件到本地"><a href="#copyToLocal-下载文件到本地" class="headerlink" title="copyToLocal - 下载文件到本地"></a>copyToLocal - 下载文件到本地</h3><p>使用方法：hadoop fs -copyToLocal [-ignorecrc] [-crc] URI <localdst></localdst></p>
<p>除了限定目标路径是一个本地文件外，和<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html#getlink" target="_blank" rel="noopener"><strong>get</strong></a>命令类似。</p>
<h3 id="cp-复制文件"><a href="#cp-复制文件" class="headerlink" title="cp - 复制文件"></a>cp - 复制文件</h3><p>使用方法：hadoop fs -cp URI [URI …] <dest></dest></p>
<p>将文件从源路径复制到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。<br>示例：</p>
<ul>
<li>hadoop fs -cp /user/hadoop/file1 /user/hadoop/file2</li>
<li>hadoop fs -cp /user/hadoop/file1 /user/hadoop/file2 /user/hadoop/dir</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="du-显示-多个-文件的大小。"><a href="#du-显示-多个-文件的大小。" class="headerlink" title="du - 显示(多个)文件的大小。"></a>du - 显示(多个)文件的大小。</h3><p>使用方法：hadoop fs -du URI [URI …]</p>
<p>显示目录中所有文件的大小，或者当只指定一个文件时，显示此文件的大小。<br>示例：<br>hadoop fs -du /user/hadoop/dir1 /user/hadoop/file1 hdfs://host:port/user/hadoop/dir1<br>返回值：<br>成功返回0，失败返回-1。 </p>
<h3 id="dus-显示文件的大小"><a href="#dus-显示文件的大小" class="headerlink" title="dus - 显示文件的大小"></a>dus - 显示文件的大小</h3><p>使用方法：hadoop fs -dus <args></args></p>
<p>显示文件的大小。</p>
<h3 id="expunge-清空回收站"><a href="#expunge-清空回收站" class="headerlink" title="expunge - 清空回收站"></a>expunge - 清空回收站</h3><p>使用方法：hadoop fs -expunge</p>
<p>清空回收站。请参考<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html" target="_blank" rel="noopener">HDFS设计</a>文档以获取更多关于回收站特性的信息。</p>
<h3 id="get-复制文件到本地文件系统"><a href="#get-复制文件到本地文件系统" class="headerlink" title="get - 复制文件到本地文件系统"></a>get - 复制文件到本地文件系统</h3><p>使用方法：hadoop fs -get [-ignorecrc] [-crc] <src> <localdst> </localdst></src></p>
<p>复制文件到本地文件系统。可用-ignorecrc选项复制CRC校验失败的文件。使用-crc选项复制文件以及CRC信息。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -get /user/hadoop/file localfile</li>
<li>hadoop fs -get hdfs://host:port/user/hadoop/file localfile</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="getmerge-合并多个文件"><a href="#getmerge-合并多个文件" class="headerlink" title="getmerge - 合并多个文件"></a>getmerge - 合并多个文件</h3><p>使用方法：hadoop fs -getmerge <src> <localdst> [addnl]</localdst></src></p>
<p>接受一个源目录和一个目标文件作为输入，并且将源目录中所有的文件连接成本地目标文件。addnl是可选的，用于指定在每个文件结尾添加一个换行符。</p>
<h3 id="ls-查看某目录下的文件"><a href="#ls-查看某目录下的文件" class="headerlink" title="ls - 查看某目录下的文件"></a>ls - 查看某目录下的文件</h3><p>使用方法：hadoop fs -ls <args></args></p>
<p>如果是文件，则按照如下格式返回文件信息：<br>文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID<br>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下：<br>目录名 <dir> 修改日期 修改时间 权限 用户ID 组ID<br>示例：<br>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2 hdfs://host:port/user/hadoop/dir1 /nonexistentfile<br>返回值：<br>成功返回0，失败返回-1。 </dir></p>
<h3 id="lsr-递归查看某目录下的文件"><a href="#lsr-递归查看某目录下的文件" class="headerlink" title="lsr - 递归查看某目录下的文件"></a>lsr - 递归查看某目录下的文件</h3><p>使用方法：hadoop fs -lsr <args><br>ls命令的递归版本。类似于Unix中的ls -R。</args></p>
<h3 id="mkdir-创建-多个-目录"><a href="#mkdir-创建-多个-目录" class="headerlink" title="mkdir - 创建(多个)目录"></a>mkdir - 创建(多个)目录</h3><p>使用方法：hadoop fs -mkdir <paths> </paths></p>
<p>接受路径指定的uri作为参数，创建这些目录。其行为类似于Unix的mkdir -p，它会创建路径中的各级父目录。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -mkdir /user/hadoop/dir1 /user/hadoop/dir2</li>
<li>hadoop fs -mkdir hdfs://host1:port1/user/hadoop/dir hdfs://host2:port2/user/hadoop/dir</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="movefromLocal-剪切本地文件到hdfs"><a href="#movefromLocal-剪切本地文件到hdfs" class="headerlink" title="movefromLocal - 剪切本地文件到hdfs"></a>movefromLocal - 剪切本地文件到hdfs</h3><p>使用方法：dfs -moveFromLocal <src> <dst></dst></src></p>
<p>与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中。</p>
<h3 id="mv-将（多个）文件从源路径移动到目标路径"><a href="#mv-将（多个）文件从源路径移动到目标路径" class="headerlink" title="mv - 将（多个）文件从源路径移动到目标路径"></a>mv - 将（多个）文件从源路径移动到目标路径</h3><p>使用方法：hadoop fs -mv URI [URI …] <dest></dest></p>
<p>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。<br>示例：</p>
<ul>
<li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li>
<li>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="put-复制本地（多个）源路径到目标文件系统"><a href="#put-复制本地（多个）源路径到目标文件系统" class="headerlink" title="put - 复制本地（多个）源路径到目标文件系统"></a>put - 复制本地（多个）源路径到目标文件系统</h3><p>使用方法：hadoop fs -put <localsrc> … <dst></dst></localsrc></p>
<p>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。</p>
<ul>
<li>hadoop fs -put localfile /user/hadoop/hadoopfile</li>
<li>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</li>
<li>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</li>
<li>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile<br>从标准输入中读取输入。</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="rm-删除文件"><a href="#rm-删除文件" class="headerlink" title="rm - 删除文件"></a>rm - 删除文件</h3><p>使用方法：hadoop fs -rm URI [URI …]</p>
<p>删除指定的文件。只删除非空目录和文件。请参考rmr命令了解递归删除。<br>示例：</p>
<ul>
<li>hadoop fs -rm hdfs://host:port/file /user/hadoop/emptydir</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="rmr-递归删除文件"><a href="#rmr-递归删除文件" class="headerlink" title="rmr - 递归删除文件"></a>rmr - 递归删除文件</h3><p>使用方法：hadoop fs -rmr URI [URI …]</p>
<p>delete的递归版本。<br>示例：</p>
<ul>
<li>hadoop fs -rmr /user/hadoop/dir</li>
<li>hadoop fs -rmr hdfs://host:port/user/hadoop/dir</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="setrep-改变文件的副本系数"><a href="#setrep-改变文件的副本系数" class="headerlink" title="setrep - 改变文件的副本系数"></a>setrep - 改变文件的副本系数</h3><p>使用方法：hadoop fs -setrep [-R] <path></path></p>
<p>改变一个文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -setrep -w 3 -R /user/hadoop/dir1</li>
</ul>
<p>返回值：</p>
<p>成功返回0，失败返回-1。</p>
<h3 id="stat-返回指定路径的统计信息"><a href="#stat-返回指定路径的统计信息" class="headerlink" title="stat - 返回指定路径的统计信息"></a>stat - 返回指定路径的统计信息</h3><p>使用方法：hadoop fs -stat URI [URI …]</p>
<p>返回指定路径的统计信息。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -stat path</li>
</ul>
<p>返回值：<br>成功返回0，失败返回-1。</p>
<h3 id="tail-查看文件尾部内容"><a href="#tail-查看文件尾部内容" class="headerlink" title="tail - 查看文件尾部内容"></a>tail - 查看文件尾部内容</h3><p>使用方法：hadoop fs -tail [-f] URI</p>
<p>将文件尾部1K字节的内容输出到stdout。支持-f选项，行为和Unix中一致。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -tail pathname</li>
</ul>
<p>返回值：<br>成功返回0，失败返回-1。</p>
<h3 id="test-检查文件"><a href="#test-检查文件" class="headerlink" title="test - 检查文件"></a>test - 检查文件</h3><p>使用方法：hadoop fs -test -[ezd] URI</p>
<p>选项：<br>-e 检查文件是否存在。如果存在则返回0。<br>-z 检查文件是否是0字节。如果是则返回0。<br>-d 如果路径是个目录，则返回1，否则返回0。</p>
<p>示例：</p>
<ul>
<li>hadoop fs -test -e filename</li>
</ul>
<h3 id="text-将源文件输出为文本格式"><a href="#text-将源文件输出为文本格式" class="headerlink" title="text - 将源文件输出为文本格式"></a>text - 将源文件输出为文本格式</h3><p>使用方法：hadoop fs -text <src> </src></p>
<p>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</p>
<h3 id="touchz-创建一个0字节的空文件"><a href="#touchz-创建一个0字节的空文件" class="headerlink" title="touchz - 创建一个0字节的空文件"></a>touchz - 创建一个0字节的空文件</h3><p>使用方法：hadoop fs -touchz URI [URI …] </p>
<p>创建一个0字节的空文件。</p>
<p>示例：</p>
<ul>
<li>hadoop -touchz pathname</li>
</ul>
<p>返回值：<br>成功返回0，失败返回-1。</p>



            <!-- Pager -->
            <ul class="pager">
                
                <li class="previous">
                    <a href="/lhj/2019/03/14/SpringBoot与数据访问/">&larr; Previous Post</a>
                </li>
                
                
                <li class="next">
                    <a href="/lhj/2019/03/09/正则表达式语法/">Next Post &rarr;</a>
                </li>
                
            </ul>



        </div>
        <!-- Sidebar container-->
        <div class="
    col-lg-3 col-lg-offset-0
    col-md-3 col-md-offset-0
    col-sm-12
    col-xs-12
    sidebar-container
">
            <!-- toc -->
            <div class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix-top" role="complementary">
                <h4><i class="fa fa-bookmark"></i> Catalog</h4>
                <ul class="nav bs-docs-sidenav">

                </ul>

            </div>

        </div>
    </div>
</div>

<!-- Footer -->
<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; keep moving on 2019
                    <br>
                    Theme by <a href="http://beantech.org/">Bean Tech</a>
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    re-Ported by <a href="https://1006400320.github.io/lhj">keep moving on</a>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="https://cdn.staticfile.org/jquery/2.2.4/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/lhj/js/script.js"></script>




</body>
</html>